{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwG17Jq4LrBG",
        "outputId": "52cd020c-a998-40fd-ea2e-55ba3fb7649f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.0.post2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.7.1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (23.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (2.27.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.13.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (8.2.2)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.18.2.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Importing libraries\n",
        "\n",
        "!pip install librosa\n",
        "!pip install tqdm\n",
        "!pip install plotly\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import glob\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats\n",
        "import warnings\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "import plotly.offline as py\n",
        "\n",
        "warnings.simplefilter(\"ignore\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "py.init_notebook_mode(connected=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KLfURFNUF3g"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kcdf6R4US9p"
      },
      "outputs": [],
      "source": [
        "!cp '/content/drive/MyDrive/ravdess.zip' .\n",
        "!unzip  -q ravdess.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVqN7kIsMYtq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "def metadata(basepath):\n",
        "    df = pd.DataFrame(columns=['path', 'source', 'actor', 'gender', 'intensity', 'statement', 'repetition', 'emotion'])\n",
        "    count = 0\n",
        "\n",
        "    actor_folders = glob.glob(basepath)\n",
        "    for actor_folder in actor_folders:\n",
        "     if os.path.isdir(actor_folder):\n",
        "        try:\n",
        "            actor = int(os.path.basename(actor_folder).split('_')[-1])\n",
        "        except ValueError:\n",
        "            print(\"Invalid actor folder:\", actor_folder)\n",
        "            continue\n",
        "\n",
        "        actor_files = glob.glob(actor_folder + '/*.wav')\n",
        "        for file_path in actor_files:\n",
        "            print(\"Actor folder:\", actor_folder)  # Print the actor_folder for troubleshooting\n",
        "            actor = int(os.path.basename(actor_folder).split('_')[-1])  # Extract the actor number correctly\n",
        "            filename = os.path.basename(file_path).split('.')[0].split('-')\n",
        "            if len(filename) == 7:\n",
        "                src = int(filename[1])\n",
        "                emotion = int(filename[2])\n",
        "\n",
        "                gender = \"female\" if actor % 2 == 0 else \"male\"\n",
        "                intensity = 0 if filename[3] == '01' else 1\n",
        "                statement = 0 if filename[4] == '01' else 1\n",
        "                repeat = 0 if filename[5] == '01' else 1\n",
        "\n",
        "                df.loc[count] = [file_path, src, actor, gender, intensity, statement, repeat, emotion]\n",
        "                count += 1\n",
        "\n",
        "\n",
        "    labels = []\n",
        "    y = []\n",
        "    for i in range(len(df)):\n",
        "        if df.emotion.iloc[i] == 1:\n",
        "            label = \"_neutral\"\n",
        "            y.append(1)\n",
        "        elif df.emotion.iloc[i] == 2:\n",
        "            label = \"_calm\"\n",
        "            y.append(2)\n",
        "        elif df.emotion.iloc[i] == 3:\n",
        "            label = \"_happy\"\n",
        "            y.append(3)\n",
        "        elif df.emotion.iloc[i] == 4:\n",
        "            label = \"_sad\"\n",
        "            y.append(4)\n",
        "        elif df.emotion.iloc[i] == 5:\n",
        "            label = \"_angry\"\n",
        "            y.append(5)\n",
        "        elif df.emotion.iloc[i] == 6:\n",
        "            label = \"_fearful\"\n",
        "            y.append(6)\n",
        "        elif df.emotion.iloc[i] == 7:\n",
        "            label = \"_disgust\"\n",
        "            y.append(7)\n",
        "        elif df.emotion.iloc[i] == 8:\n",
        "            label = \"_surprised\"\n",
        "            y.append(8)\n",
        "        else:\n",
        "            label = \"_none\"\n",
        "\n",
        "        # Add gender to the label\n",
        "        labels.append(label)\n",
        "\n",
        "    df['label'] = labels\n",
        "\n",
        "    return df\n",
        "\n",
        "basepath = '/content/Actor_*'\n",
        "df = metadata(basepath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HG2qvAYePYgL"
      },
      "outputs": [],
      "source": [
        "y = df.emotion.values.tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUgYydkKrmAh"
      },
      "outputs": [],
      "source": [
        "class Spectrograms():\n",
        "    def __init__(self, df, datasettype, outputpath, sample=False, augmentation=False, mel=True, mfcc=False, spectral=False, mfccbanks=20, n_mels=128):\n",
        "        self.df = df\n",
        "        self.augmentation = augmentation\n",
        "        self.mel = mel\n",
        "        self.mfcc = mfcc\n",
        "        self.spectral = spectral\n",
        "        self.mfccbanks = mfccbanks\n",
        "        self.n_mels = n_mels\n",
        "        self.outputpath = outputpath\n",
        "        self.datasettype = datasettype\n",
        "        self.sample = sample\n",
        "\n",
        "    def get_spectrograms(self):\n",
        "        if self.sample:\n",
        "            x, sample_rate = librosa.load(self.df.index[0])\n",
        "            self.generate(x, sample_rate, '', 0)\n",
        "\n",
        "        else:\n",
        "            for file in tqdm(range(self.df.shape[0])):\n",
        "                emotion = df.iloc[file, df.columns.get_loc('label')]\n",
        "                path = self.outputpath+self.datasettype+\"/\"+str(emotion)+\"/\"\n",
        "\n",
        "                if not os.path.isdir(path):\n",
        "                    os.makedirs(path)\n",
        "\n",
        "                ## Reading signal from .wav file\n",
        "                x, sample_rate = librosa.load(self.df.index[file])\n",
        "                emo = df.iloc[file, df.columns.get_loc('emotion')]\n",
        "                self.generate(x, sample_rate, path, file, emo)\n",
        "\n",
        "\n",
        "    def generate(self, x, sample_rate, path, count, emo):\n",
        "        if self.mel:\n",
        "            mel_features = librosa.feature.melspectrogram(y=x, sr=sample_rate, n_mels=self.n_mels)\n",
        "\n",
        "            log_mel_features = librosa.power_to_db(mel_features, ref=np.max)\n",
        "            fig = plt.figure(figsize=(12,4))\n",
        "            ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "            ax.set_axis_off()\n",
        "            fig.add_axes(ax)\n",
        "            librosa.display.specshow(log_mel_features, sr=sample_rate, x_axis='time', y_axis='mel')\n",
        "            if self.sample:\n",
        "                plt.show()\n",
        "            else:\n",
        "                plt.savefig(path+str(emo)+\"-\"+str(count)+\".jpg\")\n",
        "\n",
        "                plt.close()\n",
        "\n",
        "        if self.mfcc:\n",
        "            mfcc_features = librosa.feature.mfcc(x, sr=sample_rate, n_mfcc=self.mfccbanks)\n",
        "            fig = plt.figure(figsize=(12,4))\n",
        "            ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "            ax.set_axis_off()\n",
        "            fig.add_axes(ax)\n",
        "            librosa.display.specshow(mfcc_features, sr=sample_rate, x_axis='time', y_axis='mel')\n",
        "            if self.sample:\n",
        "                plt.show()\n",
        "            else:\n",
        "                plt.savefig(path+\"mfccspectrogram_\"+str(count)+\".jpg\")\n",
        "                plt.close()\n",
        "\n",
        "        if self.spectral:\n",
        "            spectral_features = librosa.feature.spectral_contrast(x, sr=sample_rate)\n",
        "            fig = plt.figure(figsize=(12,4))\n",
        "            ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "            ax.set_axis_off()\n",
        "            fig.add_axes(ax)\n",
        "            librosa.display.specshow(spectral_features, sr=sample_rate, x_axis='time', y_axis='mel')\n",
        "            if self.sample:\n",
        "                plt.show()\n",
        "            else:\n",
        "                plt.savefig(path+\"spectralspectrogram_\"+str(count)+\".jpg\")\n",
        "                plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhcQ43fYL6I5"
      },
      "outputs": [],
      "source": [
        "df_new = metadata('/content/Actor_*')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voG8XX84MKS5"
      },
      "outputs": [],
      "source": [
        "df_new.index = df_new.path\n",
        "df_new = df_new.drop(\"path\", axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNFzbUXEMSe_"
      },
      "outputs": [],
      "source": [
        "spectrograms = Spectrograms(df_new, 'images_new', '/content/spectrograms', sample=False)\n",
        "spectrograms.get_spectrograms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRQktDf6hJ0O"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWstTcXnNt9l"
      },
      "outputs": [],
      "source": [
        "categories = os.listdir(\"/content/spectrogramsimages_new\")\n",
        "len(categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Wn7cuRjNxdW"
      },
      "outputs": [],
      "source": [
        "def load_images_and_labels(categories):\n",
        "    img_lst=[]\n",
        "    labels=[]\n",
        "    for index, category in enumerate(categories):\n",
        "        for image_name in os.listdir(fpath+\"/\"+category):\n",
        "            img = cv2.imread(fpath+\"/\"+category+\"/\"+image_name)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            img_array = Image.fromarray(img, 'RGB')\n",
        "\n",
        "            #resize image to 224 x 224 because the input image resolution for GoogleNet is 224 x 224\n",
        "            resized_img = img_array.resize((224, 224))\n",
        "\n",
        "            img_lst.append(np.array(resized_img))\n",
        "\n",
        "            labels.append(index)\n",
        "    return img_lst, labels\n",
        "\n",
        "fpath = \"/content/spectrogramsimages_new\"\n",
        "images, labels = load_images_and_labels(categories)\n",
        "print(\"No. of images loaded = \",len(images),\"\\nNo. of labels loaded = \",len(labels))\n",
        "print(type(images),type(labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSCFSL_ngfPr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNtyz5pFOXM6"
      },
      "outputs": [],
      "source": [
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"Images shape = \",images.shape,\"\\nLabels shape = \",labels.shape)\n",
        "print(type(images),type(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JehRAdlwOdlw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYjRmFm4Od4S"
      },
      "outputs": [],
      "source": [
        "#1-step in data shuffling\n",
        "random_seed=42\n",
        "#get equally spaced numbers in a given range\n",
        "n = np.arange(images.shape[0])\n",
        "print(\"'n' values before shuffling = \",n)\n",
        "\n",
        "#shuffle all the equally spaced values in list 'n'\n",
        "np.random.seed(random_seed)\n",
        "np.random.shuffle(n)\n",
        "print(\"\\n'n' values after shuffling = \",n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNxwAtpjOk77"
      },
      "outputs": [],
      "source": [
        "#2-step in data shuffling\n",
        "\n",
        "#shuffle images and corresponding labels data in both the lists\n",
        "images = images[n]\n",
        "labels = labels[n]\n",
        "\n",
        "print(\"Images shape after shuffling = \",images.shape,\"\\nLabels shape after shuffling = \",labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUlPJkVaOtkK"
      },
      "outputs": [],
      "source": [
        "images = images.astype(np.float32)\n",
        "labels = labels.astype(np.int32)\n",
        "images = images/255\n",
        "print(\"Images shape after normalization = \",images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNC7tjgvRNLW"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.2, random_state = random_seed)\n",
        "\n",
        "print(\"x_train shape = \",x_train.shape)\n",
        "print(\"y_train shape = \",y_train.shape)\n",
        "print(\"\\nx_test shape = \",x_test.shape)\n",
        "print(\"y_test shape = \",y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juhtm3U9RXCm"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEnWXG31UIOZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dropout, Dense, Flatten, BatchNormalization, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "def InceptionModule(layer, filters):\n",
        "    branch1 = Conv2D(filters[0], (1, 1), padding='same', activation='relu')(layer)\n",
        "\n",
        "    branch2 = Conv2D(filters[1], (1, 1), padding='same', activation='relu')(layer)\n",
        "    branch2 = Conv2D(filters[2], (3, 3), padding='same', activation='relu')(branch2)\n",
        "\n",
        "    branch3 = Conv2D(filters[3], (1, 1), padding='same', activation='relu')(layer)\n",
        "    branch3 = Conv2D(filters[4], (5, 5), padding='same', activation='relu')(branch3)\n",
        "\n",
        "    branch4 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(layer)\n",
        "    branch4 = Conv2D(filters[5], (1, 1), padding='same', activation='relu')(branch4)\n",
        "\n",
        "    output = concatenate([branch1, branch2, branch3, branch4], axis=-1)\n",
        "    return output\n",
        "\n",
        "input_layer = Input(shape=(224, 224, 3))\n",
        "\n",
        "# Stage 1\n",
        "x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', activation='relu')(input_layer)\n",
        "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "# Stage 2\n",
        "x = Conv2D(64, (1, 1), activation='relu')(x)\n",
        "x = Conv2D(192, (3, 3), padding='same', activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "# Inception modules (3a, 3b, 3c)\n",
        "x = InceptionModule(x, [64, 96, 128, 16, 32, 32])\n",
        "x = InceptionModule(x, [128, 128, 192, 32, 96, 64])\n",
        "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "x = InceptionModule(x, [192, 96, 208, 16, 48, 64])\n",
        "x = InceptionModule(x, [160, 112, 224, 24, 64, 64])\n",
        "x = InceptionModule(x, [128, 128, 256, 24, 64, 64])\n",
        "x = InceptionModule(x, [112, 144, 288, 32, 64, 64])\n",
        "x = InceptionModule(x, [256, 160, 320, 32, 128, 128])\n",
        "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "x = InceptionModule(x, [256, 160, 320, 32, 128, 128])\n",
        "x = InceptionModule(x, [384, 192, 384, 48, 128, 128])\n",
        "x = AveragePooling2D(pool_size=(7, 7), strides=(1, 1), padding='valid')(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(1000, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "output = Dense(20, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otlGSOZWUTpw"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ywvy2W7HUVhX"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "model.fit(x_train, y_train, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV6qnRYFUZED"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V57c2cfff3Hs"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(x_test)\n",
        "predicted_classes = np.argmax(predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6e-xByngDap"
      },
      "outputs": [],
      "source": [
        "predictions\n",
        "y_test\n",
        "new_Ytest = y_test.astype(int)\n",
        "new_Ytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9T4eKsEgDzy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = classification_report(new_Ytest, predicted_classes)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbgRzMiXgXwx"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "new_Ytest = new_Ytest.astype(int)\n",
        "matrix = confusion_matrix(new_Ytest, predicted_classes)\n",
        "print(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4dHb0axgcWY"
      },
      "outputs": [],
      "source": [
        "# pred = model.predict(x_test)\n",
        "# plt.figure(1 , figsize = (19 , 10))\n",
        "# n = 0\n",
        "\n",
        "# for i in range(9):\n",
        "#     n += 1\n",
        "#     r = np.random.randint( 0, x_test.shape[0], 1)\n",
        "\n",
        "#     plt.subplot(3, 3, n)\n",
        "#     plt.subplots_adjust(hspace = 0.3, wspace = 0.3)\n",
        "\n",
        "#     plt.imshow(x_test[r[0]])\n",
        "#     plt.title('Actual = {}, Predicted = {}'.format(y_test[r[0]] , y_test[r[0]]*pred[r[0]][y_test[r[0]]]) )\n",
        "#     plt.xticks([]) , plt.yticks([])\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV4nzgcjgnqO"
      },
      "outputs": [],
      "source": [
        "# from keras.layers import Dense, Flatten, Reshape, Input, InputLayer\n",
        "# from keras.models import Sequential, Model\n",
        "\n",
        "# def build_autoencoder(img_shape, code_size):\n",
        "#     # The encoder\n",
        "#     encoder = Sequential()\n",
        "#     encoder.add(InputLayer(img_shape))\n",
        "#     encoder.add(Flatten())\n",
        "#     encoder.add(Dense(code_size))\n",
        "\n",
        "#     # The decoder\n",
        "#     decoder = Sequential()\n",
        "#     decoder.add(InputLayer((code_size,)))\n",
        "#     decoder.add(Dense(np.prod(img_shape))) # np.prod(img_shape) is the same as 32*32*3, it's more generic than saying 3072\n",
        "#     decoder.add(Reshape(img_shape))\n",
        "\n",
        "#     return encoder, decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hS0fYUQbgz6O"
      },
      "outputs": [],
      "source": [
        "# IMG_SHAPE = images.shape[1:]\n",
        "# encoder, decoder = build_autoencoder(IMG_SHAPE, 32)\n",
        "\n",
        "# inp = Input(IMG_SHAPE)\n",
        "# code = encoder(inp)\n",
        "# reconstruction = decoder(code)\n",
        "\n",
        "# autoencoder = Model(inp,reconstruction)\n",
        "# autoencoder.compile(optimizer='adamax', loss='mse')\n",
        "\n",
        "# print(autoencoder.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zqdGvj4g8K5"
      },
      "outputs": [],
      "source": [
        "# history = autoencoder.fit(x=x_train, y=x_train, epochs=20,\n",
        "#                 validation_data=[x_test, x_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98UYaju1hIeu"
      },
      "outputs": [],
      "source": [
        "# decoded_imgs = autoencoder.predict(images)\n",
        "\n",
        "# n = 1\n",
        "# plt.figure(figsize=(20, 4))\n",
        "# for i in range(n):\n",
        "#     # display original\n",
        "#     ax = plt.subplot(2, n, i+1)\n",
        "#     plt.imshow(x_test[i].reshape(224, 224,3))\n",
        "#     plt.gray()\n",
        "#     ax.get_xaxis().set_visible(False)\n",
        "#     ax.get_yaxis().set_visible(False)\n",
        "\n",
        "#     # display reconstruction\n",
        "#     ax = plt.subplot(2, n, i + n+1)\n",
        "#     plt.imshow(decoded_imgs[i].reshape(224, 224,3))\n",
        "#     plt.gray()\n",
        "#     ax.get_xaxis().set_visible(False)\n",
        "#     ax.get_yaxis().set_visible(False)\n",
        "# plt.show()\n",
        "\n",
        "# print(\"Accuracy=\",1-np.mean(abs(images-decoded_imgs)),'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfeHze2Kka3o"
      },
      "outputs": [],
      "source": [
        "# decoded_imgs = autoencoder.predict(images)\n",
        "# n = 1\n",
        "# plt.figure(figsize=(20, 4))\n",
        "# for i in range(n):\n",
        "#     # display original\n",
        "#     ax = plt.subplot(2, n, i+1)\n",
        "#     plt.imshow(images[i].reshape(224, 224,3))\n",
        "#     plt.gray()\n",
        "#     ax.get_xaxis().set_visible(False)\n",
        "#     ax.get_yaxis().set_visible(False)\n",
        "\n",
        "#     # display reconstruction\n",
        "#     ax = plt.subplot(2, n, i + n+1)\n",
        "#     plt.imshow(decoded_imgs[i].reshape(224, 224,3))\n",
        "#     plt.gray()\n",
        "#     ax.get_xaxis().set_visible(False)\n",
        "#     ax.get_yaxis().set_visible(False)\n",
        "# plt.show()\n",
        "\n",
        "# print(\"Accuracy=\",1-np.mean(abs(images-decoded_imgs)),'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDCimXkIpR21"
      },
      "outputs": [],
      "source": [
        "# X_train, X_test, Y_train, Y_test = train_test_split(decoded_imgs, labels, test_size = 0.2, random_state = random_seed)\n",
        "\n",
        "# print(\"x_train shape = \",X_train.shape)\n",
        "# print(\"y_train shape = \",Y_train.shape)\n",
        "# print(\"\\nx_test shape = \",X_test.shape)\n",
        "# print(\"y_test shape = \",Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xdFJasNpeRv"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# model.fit(X_train, Y_train, epochs=100, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvkACaljXQPG"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6Y84VJvXSSW"
      },
      "outputs": [],
      "source": [
        "predictions_new = np.argmax(model.predict(x_test), axis=-1)\n",
        "predictions_new\n",
        "y_test\n",
        "new_Ytest_new = y_test.astype(int)\n",
        "new_Ytest_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mWyOJoFXZw_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(new_Ytest_new, predictions_new)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0zYz7iVXZz2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, matthews_corrcoef\n",
        "\n",
        "report = classification_report(new_Ytest_new, predictions_new)\n",
        "print(report)\n",
        "\n",
        "# Calculate MCC for each emotion\n",
        "emotions = [0, 1, 2, 3, 4, 5, 6, 7]  # Replace with your actual emotion labels\n",
        "mcc_scores = {}\n",
        "for emotion in emotions:\n",
        "    emotion_indices = (new_Ytest_new == emotion)\n",
        "    emotion_predictions = predictions_new[emotion_indices]\n",
        "    emotion_labels = new_Ytest_new[emotion_indices]\n",
        "    mcc_scores[emotion] = matthews_corrcoef(emotion_labels, emotion_predictions)\n",
        "\n",
        "# Print MCC scores for each emotion\n",
        "for emotion, mcc in mcc_scores.items():\n",
        "    print(f\"MCC for emotion {emotion}: {mcc}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yl3w9DXmXnGu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Train the model and obtain the history object\n",
        "history = model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test))\n",
        "\n",
        "# Plot the accuracy curve\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot the loss curve\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}